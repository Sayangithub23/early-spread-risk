{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a92c23b",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cebc2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime, timezone\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ac900",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9d195c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"spread_risk_model.joblib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd212150-f07f-4f87-99c8-b4f0914b84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read only: True\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(\n",
    "    client_id=\"Lr6Uh2UAq-JI_zjFEs0K4g\",\n",
    "    client_secret=\"-QFAmBnQ-ihiJSaauZaQymfKTf_qKw\",\n",
    "    user_agent=\"violence-dataset-scraper:v1.2\"\n",
    ")\n",
    "\n",
    "print(\"Read only:\", reddit.read_only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec202a",
   "metadata": {},
   "source": [
    "### Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c445668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(reactions):\n",
    "    children = defaultdict(list)\n",
    "    for r in reactions:\n",
    "        if r[\"parent\"]:\n",
    "            children[r[\"parent\"]].append(r[\"id\"])\n",
    "    return children\n",
    "\n",
    "def cascade_depth(node, children, depth=0):\n",
    "    if node not in children:\n",
    "        return depth\n",
    "    return max(cascade_depth(child, children, depth + 1)\n",
    "               for child in children[node])\n",
    "\n",
    "def cascade_width(children):\n",
    "    return max((len(v) for v in children.values()), default=0)\n",
    "\n",
    "def early_reactions(reactions, source_time, minutes):\n",
    "    cutoff = source_time.timestamp() + minutes * 60\n",
    "    return sum(1 for r in reactions if r[\"time\"].timestamp() <= cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622b65b",
   "metadata": {},
   "source": [
    "### Predict Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ed39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_reddit_spread_risk(url):\n",
    "    submission = reddit.submission(url=url)\n",
    "    submission.comments.replace_more(limit=0)\n",
    "\n",
    "    source_time = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc)\n",
    "\n",
    "    reactions = []\n",
    "    for c in submission.comments.list():\n",
    "        reactions.append({\n",
    "            \"id\": c.id,\n",
    "            \"parent\": c.parent_id.replace(\"t1_\", \"\").replace(\"t3_\", \"\"),\n",
    "            \"time\": datetime.fromtimestamp(c.created_utc, tz=timezone.utc)\n",
    "        })\n",
    "\n",
    "    children = build_tree(reactions)\n",
    "\n",
    "    features = {\n",
    "        \"total_reactions\": len(reactions),\n",
    "        \"reactions_30min\": early_reactions(reactions, source_time, 30),\n",
    "        \"reactions_60min\": early_reactions(reactions, source_time, 60),\n",
    "        \"cascade_depth\": cascade_depth(submission.id, children),\n",
    "        \"cascade_width\": cascade_width(children),\n",
    "\n",
    "        # user features unavailable on Reddit â†’ set 0 (same as training)\n",
    "        \"tweets_per_day\": 0,\n",
    "        \"avg_gap_minutes\": 0,\n",
    "        \"burstiness\": 0,\n",
    "        \"topic_entropy\": 0,\n",
    "    }\n",
    "\n",
    "    X = pd.DataFrame([features])\n",
    "\n",
    "    pipeline = joblib.load(MODEL_PATH)\n",
    "    risk_prob = pipeline.predict_proba(X)[0][1]\n",
    "\n",
    "    return features, risk_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bad3c0",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85f94a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Extracted Features ===\n",
      "     total_reactions: 63\n",
      "     reactions_30min: 1\n",
      "     reactions_60min: 63\n",
      "       cascade_depth: 4\n",
      "       cascade_width: 31\n",
      "      tweets_per_day: 0\n",
      "     avg_gap_minutes: 0\n",
      "          burstiness: 0\n",
      "       topic_entropy: 0\n",
      "\n",
      "=== RESULT ===\n",
      "Spread Risk Probability: 1.000\n",
      "RISK: HIGH\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = input(\"Paste Reddit thread URL:\\n\").strip()\n",
    "    feats, prob = predict_reddit_spread_risk(url)\n",
    "\n",
    "    print(\"\\n=== Extracted Features ===\")\n",
    "    for k, v in feats.items():\n",
    "        print(f\"{k:>20}: {v}\")\n",
    "\n",
    "    print(\"\\n=== RESULT ===\")\n",
    "    print(f\"Spread Risk Probability: {prob:.3f}\")\n",
    "    print(\"RISK:\", \"HIGH\" if prob >= 0.5 else \"LOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021a613",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
